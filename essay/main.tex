\documentclass[UTF8,a4paper,10 pt]{article}%字符标准，纸张，字体大小，文档类型，自行打印11pt，单位打印12pt
\usepackage{mathtools,amssymb,array,amsthm,amsmath}%数学宏包
\usepackage{geometry,ulem,graphicx,longtable,caption2,cite,fancyhdr,multicol,color}%通用宏包
\geometry{a4paper,left=2cm, right=2cm, top=2.6cm, bottom=3cm}%页面布局
\usepackage{ctex}
\usepackage{multirow} % Required for multirows
\newcommand\dd{\mathop{}\!\mathrm{d}}%定义微分算子
\newcommand\eu{\mathrm{e}}%定义自然常数
\newcommand\cbnt{\mathrm{C}}%定义自然常数\\
\newcommand\argm{\mathrm{A}}%定义自然常数
\renewcommand\bar{\overline}
\renewcommand\vec{\overrightarrow}
\usepackage{graphicx,graphics}
\usepackage{wrapfig}
\usepackage{xeCJK}

\usepackage{booktabs}
\usepackage[hidelinks]{hyperref}
\xeCJKsetup{
	CJKecglue={\:}
}
\AtBeginDocument{
	\let\mathbb\relax
	\DeclareMathAlphabet{\mathbb}{U}{msb}{m}{n}
}
\setlength{\lineskip}{8pt}
\setlength{\lineskiplimit}{8pt}




\usepackage{listings}
\usepackage{xcolor}
\lstset{
	basicstyle=\small\ttfamily,	% 基本样式
	keywordstyle=\color{blue!70!green}, % 关键词样式
	commentstyle=\color{yellow!30!green!70},   	% 注释样式
	stringstyle=\color{red!70!purple}, 	% 字符串样式
	backgroundcolor=\color{gray!5},     % 代码块背景颜色
	frame=leftline,						% 代码框形状
	framerule=18pt,%
	rulecolor=\color{purple!10!blue!10},      % 代码框颜色
	numbers=left,				% 左侧显示行号往左靠, 还可以为right ，或none，即不加行号
	numberstyle=\footnotesize,	% 行号的样式
	firstnumber=1,
	stepnumber=1,                  	% 若设置为2，则显示行号为1,3,5
	numbersep=7pt,               	% 行号与代码之间的间距
	aboveskip=.25em, 			% 代码块边框
	showspaces=false,               	% 显示添加特定下划线的空格
	showstringspaces=false,         	% 不显示代码字符串中间的空格标记
	keepspaces=true, 					
	showtabs=false,                 	% 在字符串中显示制表符
	tabsize=2,                     		% 默认缩进2个字符
	captionpos=n,                   	% 将标题位置设置为底部
	flexiblecolumns=true, 			%
	breaklines=true,                	% 设置自动断行
	breakatwhitespace=false,        	% 设置自动中断是否只发生在空格处
	breakautoindent=true,			%
	breakindent=1em, 			%
	title=\lstname,				%
	escapeinside=``,  			% 在``里显示中文
	xleftmargin=1.5em,  xrightmargin=0em,     % 设定listing左右的空白
	aboveskip=1ex, belowskip=1ex,
	framextopmargin=1pt, framexbottommargin=1pt,
    abovecaptionskip=-2pt,belowcaptionskip=3pt,
	% 设定中文冲突，断行，列模式，数学环境输入，listing数字的样式
	extendedchars=false, columns=flexible, mathescape=true,
	texcl=true,
	fontadjust
}%

\allowdisplaybreaks[4]






\begin{document}
	\setlength{\lineskip}{8pt}
	\setlength{\lineskiplimit}{8pt}
    
\begin{table*}[!ht]
    \renewcommand\arraystretch{1.5}
    \centering  
    \begin{tabular}{|p{3.5cm}<{\centering}|p{3.5cm}<{\centering}|}
        \hline
        {队伍编号}&MC2406053\\
        \hline
        题号&C\\
        \hline        
    \end{tabular}
\end{table*}

\setcounter{page}{1}
\pagenumbering{roman}

\noindent\rule{\linewidth}{1pt}
\begin{center}
    \Large 基于随机森林和PulP的物流预测和人员安排
\end{center}
\begin{center}
    \large\bf 摘要
\end{center}

摘要内容

\noindent{\bf 关键词:随机森林算法、LSTM、ARIMA（SARIMA）、独热编码、PuLP}


\newpage

\tableofcontents


\newpage
\setcounter{page}{1}
\pagenumbering{arabic}


\section{问题重述}
\subsection{问题背景}
随着网购的流行，电商物流显得更加重要。在电商物流网络中，订单配送的过程包括多个环节，其中核心环节之一是分拣。分拣中心负责根据不同的目的地对包裹进行分类，并将它们发送到下一个目的地，最终交付给顾客。因此，提高分拣中心的管理效率对整个网络的订单交付效率和成本控制至关重要。

货量预测在电商物流网络中扮演着至关重要的角色。准确预测分拣中心的货物量是后续管理和决策的基础。通常，货量预测是根据历史货物量、物流网络配置等信息，来预测每个分拣中心每天和每小时的货物量。

分拣中心的货量预测与网络的运输线路密切相关。通过分析各线路的运输货物量，可以确定各分拣中心之间的网络连接关系。当线路关系发生变化时，可以根据调整信息来提高对各分拣中心货量的准确预测。

基于货量预测的人员排班是下一步需要解决的重要问题。分拣中心的人员包括正式员工和临时工两种类型。合理安排人员旨在完成工作的前提下尽可能降低人力成本。根据物流网络的情况，制定了人员安排的班次和小时人效指标。在确定人员安排时，优先考虑使用正式员工，必要时再增加临时工。

\subsection{问题描述}
\subsubsection{问题一}
根据所给的前3个月每天的货量数据以及前一个月每一个小时的货量数据建立货量预测模型，对 57 个分拣中心未来 30 天每天及每小时的货量进行预测。

\subsubsection{问题二}
由于分拣中心之间存在货物运送的关联，在已知过去三个月内的货物运输关联情况下，若运输关系发生变化，预测分拣中心的货量变化。
\subsection{总体思路分析}

\clearpage
\section{问题一的建模与求解}
\subsection{分析}
问题一给出了分拣中心在过去的四个月内每天的货量以及过去30天内每个小时的货量。在这些数据的基础上要对下一个月（30天）的货量进行预测，我们先对给出的数据进行观察。我们选取，例如{\tt SC6,SC41} 来观察。利用{\tt python/matplotlib}作图

\begin{figure}[!ht]
	\centering
	\includegraphics*[width=0.8\linewidth]{images/example.pdf}
	\caption{{\tt SC6,SC41}的日期-货量图线}
\end{figure}

根据观察，我们发现在特定的时间段会出现一些"异常值"，而这些异常值的出现很可能是由于节假日等因素引起的。因此为了预测30天后的货物量，我们选取几种深度学习的方法来进行预测。
\begin{enumerate}
	\item LSTM
	\item ARIMA
	\item 随机森林算法
\end{enumerate}
\subsubsection{LSTM}
长短期记忆（英语：Long Short-Term Memory，LSTM）是一种时间循环神经网络（RNN）。由于独特的设计结构，LSTM适合于处理和预测时间序列中间隔和延迟非常长的重要事件。LSTM 通过引入“门”结构来调节信息的流动，这使得它在长序列数据上表现得更好。LSTM的核心组件有遗忘门（Forget Gate）、输入门（Input Gate）、细胞状态（Cell State）、输出门（Output Gate）。LSTM 的每个时刻会通过上述四个门控制信息的流动。遗忘门决定丢弃哪些过去的信息，输入门和它的候选值共同决定将哪些新信息加入细胞状态。细胞状态随后更新，最后通过输出门确定应输出什么信息。

通过这样的结构，LSTM 能够在处理序列数据时有效地保留长期依赖信息，解决了传统RNN在长序列上的梯度消失或爆炸问题。

\subsubsection{ARIMA}
ARIMA模型（自回归积分滑动平均模型）是一种广泛应用于时间序列预测的统计模型。ARIMA模型结合了自回归（AR）、差分（I）和移动平均（MA）三种主要组成部分，适用于分析和预测具有时间依赖性的数据。其核心组件包括自回归（AR）部分、差分（I）部分、移动平均（MA）部分。将这三部分结合起来，ARIMA模型的完整形式可以表示为：
\begin{align*}
	\phi (B)\nabla^d X_t = \theta(B)a_t
\end{align*}
其中\(\phi (B) X_t = \phi_1X_{t-1}+\phi_2X_{t-2}+\cdots+\phi_p X_{t-p}\)，$p$是自回归项的阶数,\(\phi_i\)是自回归系数，\(B\)是退后算子。\(\theta(B) 	a_t\)则类似，\(a_t\)是时间序列的误差项。

从式子中可以看出，通过对原始数据进行差分转换，ARIMA能够将非平稳时间序列转换为平稳时间序列，因此模型能够适用于预测那些显示出趋势或季节性模式的数据。
\subsubsection{随机森林算法}
随机森林是一种集成学习方法，特别适合用于分类、回归和其他任务，通过构建多棵决策树在训练时并输出模式的类（分类）或平均预测（回归）。随机森林算法的核心思想是通过合并多个决策树的预测结果来提高整体模型的预测准确性和稳定性。


随机森林算法的主要步骤有：自助采样（Bootstrap sampling），从原始数据集中随机（允许重复的）选择N个样本构成了一个训练集。N次采样产生的N个训练集被用于训练N棵决策树
；构建决策树：对于每棵树的每个节点，随机选择k个特征（而不是所有特征），然后使用这些特征中的最佳分割方法来分割节点。这种“特征随机选择”的做法增加了树之间的差异性。
决策树的生长：每棵树都尽可能地生长而不进行剪枝。每棵树都完全依赖于自助采样得到的训练数据集来建立。
聚合预测：对于分类问题，使用多数投票法；对于回归问题，计算所有树的输出值的平均值。

随机森林算法的成功在于它的简单性和在多种数据集上表现出的高效性与准确性。它既能处理分类问题，也能处理回归问题，同时还能进行特征选择，是一种非常强大且灵活的机器学习算法。虽然随机森林通常不如专门的时间序列或图数据模型那样直接适用于处理分拣中心之间的货物流动问题，但它仍然可以在某些情况下提供有价值的见解和预测，特别是随机森林可以提供关于哪些特征（例如历史货物流量、时间因素、分拣中心之间的距离等）对预测货物流量最有影响的洞察。这对于理解货物流量模式和优化物流网络可能非常有用。


\subsection{按天的数据模拟与预测}
根据选择，我们对其进行数据模拟。我们通过使用{\tt python}的{\tt sklearn}中提供的模型来进行拟合。首先我们通过分类不同的仓库，获取所有的信息。在分类完成之后，我们利用几种方法来实现。首先是利用LSTM来生成预测的曲线。\footnote{具体代码在附录中。}如图\ref{lstm}。

相同的，我们选取随机森林进行预测可以得到图\ref{rf}。另外由于我们发现数据有较大的波动，而ARIMA 模型适用于平稳时间序列，而从图中看，原始数据不是平稳的。因此直接使用 ARIMA 模型可能不会得到好的预测效果。我们尝试季节性 ARIMA (SARIMA) 模型。

经过所输出的平均方差的对比，我们认为使用随机森林算法对于第一题是相对的最优解。因此我们对未来一个月之内每一个小时的货量预测也采取完全相同的方法预测。



\begin{figure}[t]
	\centering
	\includegraphics*[width=0.8\linewidth]{images/LSTM_R.pdf}
	\caption{利用LSTM预测图线示例}
	\label{lstm}
\end{figure}
\begin{figure}[!ht]
	\centering
	\includegraphics*[width=0.8\linewidth]{images/pre_10.pdf}
	\caption{利用随机森林预测图线示例（SC10）}
	\label{rf}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics*[width=0.8\linewidth]{images/pre_55.pdf}
	\caption{利用SARIMA预测图线示例（SC55）}
	\label{sarima}
\end{figure}

\subsection{按小时的数据模拟和预测}
按照之前的方法，相似的预测之后的数据，如图\ref{SC4_2}。从图中可以看出，拟合效果符合数据波动的周期性。通过计算拟合模型与真实数据之间的平均方差，我们确定使用随机森林算法来拟合数据。

\begin{figure}[!ht]
	\centering
	\includegraphics*[width=0.9\linewidth]{images/SC_4_2.pdf}
	\caption{利用随机森林模型预测小时图线示例（SC4）}
	\label{SC4_2}
\end{figure}


\section{问题二的建模与求解}
\subsection{分析与建模求解}
我们需要对已知的关系进行分析。因此我们首先先将仓库之间的关联进行可视化，我们选用弦图的形式，如图\ref{xt}。在现有的运输关系模型上发生了变动，此时我们需要考虑将数据预处理、特征提取、模型训练和预测。
\begin{figure}[!t]
	\centering
	\includegraphics*[width=0.8\linewidth]{images/xuantu.pdf}
	\caption{分配中心之间的关系弦图}
	\label{xt}
\end{figure}
\subsubsection{数据预处理}
首先我们需要使用独热编码将分类变量转换为数值。独热编码（One-Hot Encoding）是一种处理分类数据的常用方法，尤其适用于机器学习模型中，因为许多算法更好地处理数值数据而不是文本数据。在独热编码中，每个类别值都被转换为一个二进制向量，该向量中只有一个位置是1，其余位置都是0。在这个问题中独热编码被用于“分拣中心”这个分类特征。这样做可以将这些文本标签转换为模型可解释的数值格式，同时保持不同分拣中心之间的独立性。

\subsubsection{时间序列预测}

时间序列预测主要涉及根据过去的数据点预测未来的值，也就是将时间转换为一个可以作为模型输入的特征。在这里我们将日期时间对象转换为相对于起始时间点的总秒数来表示的，这种转换使得模型能够理解时间的线性进展。

\subsubsection{随机森林回归}
接下俩首先将时间（完整时间）转换为自起始时间以来的总秒数，这样可以将问题转换为一个回归问题，其中输入特征是连续的时间值。齐次模型训练中使用上述时间特征和历史货量数据训练随机森林模型。最后将未来的时间点同样转换为自起始时间以来的总秒数，使用训练好的随机森林模型预测这些时间点的货量。

这种方法利用了随机森林的强大能力来处理可能的非线性关系，并可以很好地应对由于特征与目标之间复杂关系造成的预测挑战。


\section{问题三的建模与求解}

\subsection{分析}

\begin{table}[!ht]
\caption{符号说明}%标题 
\centering%把表居中
\begin{tabular}{p{3cm}<{\centering}p{11cm}<{\centering}}%四个c代表该表一共四列，内容全部居中
\toprule%第一道横线
符号&说明 \\
\midrule%第二道横线 
$R(i,j,k)$&表示第 \(i\)个分拣中心在第 
$j$ 天的第 
$k$ 个班次中正式工的出勤人数。\\
$T(i,j,k)$&表示第 \(i\)个分拣中心在第 
$j$ 天的第 
$k$ 个班次中临时工的出勤人数。\\
\(v_r\)&正式员工的工作效率\\ 
\(v_t\)&临时员工的工作效率\\ 
\(t_p\)&一个班次的工作小时数\\
\bottomrule%第三道横线
\end{tabular}
\end{table}
我们的目标是最小化总人天数，即所有分拣中心在所有班次中正式工和临时工的总人数。目标函数可以写为
\begin{align*}
    {\rm Minimize\;}Z = \sum_{i}\sum_{j}\sum_{k}(R(i,j,k)+T(i,j,k))
\end{align*}

约束条件是
\begin{enumerate}
    \item 对于每个分拣中心、每个班次，正式工和临时工的总人数不得超过该班次的工作效率乘以工作小时数
    \item 对于每个分拣中心、每个班次，我们有以下约束条件：\begin{align*}
        R(i,j,k) \times v_r + T_{i,j,k} \times v_t \leq t_p
    \end{align*}
\end{enumerate}




\section{问题四的建模与求解}

\subsection{问题四的分析}

这个问题是关于如何调度员工的最优解。这是一个线性规划问题，目标是最小化总人力成本，并同时满足工作班次的需求。下面是关于一些变量的假设。


\begin{table}[!ht]
\caption{符号说明}%标题
\centering%把表居中
\begin{tabular}{p{4cm}<{\centering}p{10cm}<{\centering}}%四个c代表该表一共四列，内容全部居中
\toprule%第一道横线
符号&说明 \\
\midrule%第二道横线 
$F(i,d,s)$&二元变量，表示固定员工 $i$ 在日期 $d $和班次$ s$ 是否工作\\
$T(d,s)$&整数变量，表示在日期 $d $和班次 $s $需要的临时工人数\\
$D(d,s)$&整数变量，表示在日期 $d $和班次 $s $所需的工作需求\\
\bottomrule%第三道横线
\end{tabular}
\end{table}
我们的目标函数是
\begin{align*}
    {\rm Minimize}\quad Z =\sum_{d\in {\rm Dates}}\sum_{s\in {\rm Shifts}}\left(\sum_{i = 1}^{200}F(i,d,s)+T(d,s)\right)
\end{align*}
即最小化全职和临时工的总人天数。这个最小化函数需要满足以下几个约束条件：
\begin{enumerate}
    \item 需求满足：\begin{align*}
        \forall d\in {\rm Dates},\forall s\in {\rm Shifts}:\sum_{i = 1}^{200}F(i,d,s)+20\times T(d,s)\geq D(d,s)
    \end{align*}
    这个约束确保每个班次的工作需求被满足。这里，25和20是每个工作的产出（或能力）。
    \item 正式工出勤率不超过85\%: \begin{align*}
        \forall i:\sum_{d\in {\rm Dates}}\sum_{s\in {\rm Shifts}}F(i,d,s)\leq 30 \times 0.85
    \end{align*}此约束限制每个全职员工在一个月内的最大工作天数。
    \item 连续工作天数不超过7天:\begin{align*}
        \forall i,\forall d\in {\rm Dates\; if \;} d+6 \leq{\rm len(Dates):}\sum_{k =0}^6\sum_{s\in {\rm Shifts}}   F(i,d+k,s)\leq 7
    \end{align*}这确保任何全职员工在连续7天内的工作天数不超过7天。
\end{enumerate}

\subsection{建模求解}
针对这个问题，我们选择开源的Python/PuLP库求解。PuLP 作为一个Python库，可以定义问题、变量、目标函数和约束，然后使用 CBC 或其他求解器求解这些问题。这里我们选择在 PuLP 库中调用 CBC（Coin-or branch and cut）解决这个问题。

由于数量较大，我们设置了一个容忍度\(0.001\%\)，这是我们在这个容忍度下得到的结果。
\begin{lstlisting}
Result - Optimal solution found (within gap tolerance)

Objective value:                204322.00000000
Lower bound:                    204196.332
Gap:                            0.00
Enumerated nodes:               0
Total iterations:               0
Time (CPU seconds):             1.64
Time (Wallclock seconds):       1.85

Option for printingOptions changed from normal to all
Total time (CPU seconds):       1.72   (Wallclock seconds):       1.94

CSV file has been saved with the scheduling results.
\end{lstlisting}










\clearpage
\begin{center}
    \huge \bf 附录
\end{center}
\appendix
\section{问题一代码}
\noindent 随机森林调参代码
\begin{lstlisting}[language=python]
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler

# 假设存在的SCid列表
data_for_sc = pd.read_csv("../../附件/附件1.csv", encoding="GB2312")
ALL_SC = list(set(data_for_sc["分拣中心"]))
existing_scs = list(map(lambda SC_: int(SC_[2:]), ALL_SC))
existing_scs.sort()


# 加载数据
def load_data(existing_scs):
    all_data = []
    for sc_id in existing_scs:
        try:
            data = pd.read_csv(f"SC{sc_id}.csv")
            data["center_id"] = sc_id
            all_data.append(data)
        except FileNotFoundError:
            print(f"File for center {sc_id} not found.")
    return pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()


# 数据清洗和预处理
def preprocess_data(data):
    data["date"] = pd.to_datetime(data["date"], errors="coerce")
    data.dropna(subset=["date", "value"], inplace=True)

    data["year"] = data["date"].dt.year
    data["month"] = data["date"].dt.month
    data["day"] = data["date"].dt.day
    data["weekday"] = data["date"].dt.weekday

    scaler = StandardScaler()
    data[["year", "month", "day", "weekday"]] = scaler.fit_transform(
        data[["year", "month", "day", "weekday"]]
    )

    return data


# 模型训练和参数调整
def train_and_optimize_model(X_train, y_train):
    param_grid = {
        "n_estimators": [100 * i for i in range(1, 10)],
        "max_depth": [10 * i for i in range(1, 10)],
        "min_samples_split": [10 * i for i in range(1, 10)],
    }
    model = RandomForestRegressor(random_state=42)
    grid_search = GridSearchCV(
        model, param_grid, cv=5, scoring="neg_mean_squared_error", verbose=2
    )
    grid_search.fit(X_train, y_train)

    print("Best parameters:", grid_search.best_params_)
    return grid_search.best_estimator_


if __name__ == "__main__":
    data = load_data(existing_scs)
    if not data.empty:
        data = preprocess_data(data)
        features = data[["center_id", "year", "month", "day", "weekday"]]
        target = data["value"]

        X_train, X_test, y_train, y_test = train_test_split(
            features, target, test_size=0.2, random_state=42
        )

        best_model = train_and_optimize_model(X_train, y_train)

        y_pred = best_model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        print(f"Test MSE: {mse}")
    else:
        print("No data loaded, please check the data files.")
\end{lstlisting}

\noindent 随机森林训练代码
\begin{lstlisting}[language=python]
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# 假设数据已经按照分拣中心编号和日期排列好
# 每个文件名格式为 'SC{i}.csv'，其中 i 是分拣中心编号
# 假设存在的SCid列表
data_for_sc = pd.read_csv("../../附件/附件1.csv", encoding="GB2312")
ALL_SC = list(set(data_for_sc["分拣中心"]))
existing_scs = list(map(lambda SC_: int(SC_[2:]), ALL_SC))
existing_scs.sort()

# 加载数据
def load_data(existing_scs):
    all_data = []
    for i in existing_scs:
        data = pd.read_csv(f"SC{i}.csv")
        data["SC_id"] = i
        all_data.append(data)
    return pd.concat(all_data, ignore_index=True)


# 数据预处理
def preprocess(data):
    # 假设数据包含日期和货量两列，日期列名为 'date'，货量列名为 'value'
    data["date"] = pd.to_datetime(data["date"])
    data["year"] = (pd.to_datetime(data["date"])).dt.year
    data["month"] = (pd.to_datetime(data["date"])).dt.month
    data["day"] = (pd.to_datetime(data["date"])).dt.day
    data["weekday"] = (pd.to_datetime(data["date"])).dt.weekday
    return data


# 训练模型
def train_model(data):
    features = data[["SC_id", "year", "month", "day", "weekday"]]
    target = data["value"]
    X_train, X_test, y_train, y_test = train_test_split(
        features,
        target,
        test_size=0.2,
        random_state=50,

    )

    model = RandomForestRegressor(n_estimators=300, random_state=42, min_samples_split=20)
    model.fit(X_train, y_train)

    # 预测和评估
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    print(f"Mean Squared Error: {mse}")
    return model


# 预测未来的货量
def predict_future(model, start_date, num_days, existing_scs):
    future_dates = pd.date_range(start_date, periods=num_days)
    future_data = pd.DataFrame(
        {
            "date": np.repeat(future_dates, len(existing_scs)),
            "SC_id": np.tile(existing_scs, num_days),
        }
    )
    future_data = preprocess(future_data)
    features = future_data[["SC_id", "year", "month", "day", "weekday"]]
    predictions = model.predict(features)
    future_data["predicted_volume"] = predictions
    return future_data


# 保存结果到CSV
def save_predictions_to_csv(predictions, file_name):
    predictions["date"] = predictions["date"].dt.strftime("%Y/%m/%d")
    predictions.to_csv(file_name, index=False)
    print(f"Saved predictions to {file_name}")


# 主函数
def main():
    data = load_data(existing_scs)
    data = preprocess(data)
    model = train_model(data)
    future_predictions = predict_future(model, "2023-08-01", 153, existing_scs)
    save_predictions_to_csv(future_predictions, "predicted_volumes.csv")


if __name__ == "__main__":
    main()
\end{lstlisting}
ARIMA和LSTM的代码未被采用，因此仅放在支撑材料中。


\section{问题二代码}
\noindent 按小时预测
\begin{lstlisting}[language=python]
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder


def load_data():
    # 修改这里以加载附件2
    data_sc = pd.read_csv("附件2.csv", encoding="gb2312")
    data_routes = pd.read_csv("附件3.csv", encoding="gb2312")
    data_changes = pd.read_csv("附件4.csv", encoding="gb2312")
    return data_sc, data_routes, data_changes


def preprocess_data(data_sc, data_changes):
    # Combining date and hour into a single datetime column
    data_sc["完整时间"] = pd.to_datetime(
        data_sc["日期"].astype(str) + " " + data_sc["小时"].astype(str) + ":00"
    )

    # One-Hot Encoding for sorting centers
    ohe = OneHotEncoder()
    encoded_centers = ohe.fit_transform(data_sc[["分拣中心"]].astype(str)).toarray()
    center_df = pd.DataFrame(encoded_centers, columns=ohe.get_feature_names_out())
    data_sc = pd.concat([data_sc, center_df], axis=1)

    return data_sc, ohe


def predict_future_volume(data_sc, ohe, data_changes):
    # Generating data for the future date range within each hour
    start_time = data_sc["完整时间"].min()
    future_dates = pd.date_range(start=start_time, periods=744, freq="h")
    future_data = pd.DataFrame({"完整时间": future_dates})

    # Predicting future volume for each sorting center
    future_volumes = []
    centers = ohe.get_feature_names_out()
    for center in centers:
        center_data = data_sc[data_sc[center] == 1]
        if not center_data.empty:
            # Train a model to predict volume
            X = (
                (center_data["完整时间"] - start_time)
                .dt.total_seconds()
                .values.reshape(-1, 1)
            )
            y = center_data["货量"].values
            model = RandomForestRegressor(n_estimators=100, random_state=42)
            model.fit(X, y)

            # Use the model to predict future volume
            future_X = (
                (future_data["完整时间"] - start_time)
                .dt.total_seconds()
                .values.reshape(-1, 1)
            )
            future_y = model.predict(future_X)
            for date, volume in zip(future_dates, future_y):
                cleaned_center_name = center.replace("x0_分拣中心_", "")
                future_volumes.append(
                    [cleaned_center_name, date.strftime("%Y/%m/%d %H:%M"), volume]
                )

    future_volumes_df = pd.DataFrame(
        future_volumes, columns=["分拣中心", "日期时间", "货量"]
    )

    # Considering changes in routing paths from Attachment 4
    future_volumes_df.set_index(["分拣中心", "日期时间"], inplace=True)
    for index, row in data_changes.iterrows():
        from_center = "x0_分拣中心_" + row["始发分拣中心"]
        to_center = "分拣中心_" + row["到达分拣中心"]
        if from_center in centers:
            future_volumes_df.loc[(to_center,), "货量"] += (
                future_volumes_df.loc[(from_center,), "货量"] * 0.1
            )
            future_volumes_df.loc[(from_center,), "货量"] *= 0.9

    future_volumes_df.reset_index(inplace=True)
    return future_volumes_df


def main():
    data_sc, data_routes, data_changes = load_data()
    data_sc, ohe = preprocess_data(data_sc, data_changes)
    future_volumes_df = predict_future_volume(data_sc, ohe, data_changes)
    future_volumes_df.to_csv("predicted_future_volumes_hours.csv", index=False)
    print("预测完成，结果已保存到 'predicted_future_volumes_hours.csv'")


if __name__ == "__main__":
    main()
\end{lstlisting}
\noindent 按天预测
\begin{lstlisting}[language=python]
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import mean_squared_error


def load_data():
    # 加载数据
    data_sc = pd.read_csv("附件1.csv", encoding="gb2312")
    data_routes = pd.read_csv("附件3.csv", encoding="gb2312")
    data_changes = pd.read_csv("附件4.csv", encoding="gb2312")
    return data_sc, data_routes, data_changes


def preprocess_data(data_sc, data_changes):
    # 预处理数据，准备特征和标签
    data_sc["日期"] = pd.to_datetime(data_sc["日期"], format="%Y/%m/%d")

    # One-Hot Encoding 分拣中心
    ohe = OneHotEncoder()
    encoded_centers = ohe.fit_transform(data_sc[["分拣中心"]].astype(str)).toarray()
    center_df = pd.DataFrame(encoded_centers, columns=ohe.get_feature_names_out())
    data_sc = pd.concat([data_sc, center_df], axis=1)

    return data_sc, ohe


def predict_future_volume(data_sc, ohe, data_changes):
    # 生成未来日期范围内的数据
    future_dates = pd.date_range(data_sc["日期"].min(), periods=31, freq="D")
    future_data = pd.DataFrame({"日期": future_dates})

    # 预测每个分拣中心的未来货量
    future_volumes = []
    centers = ohe.get_feature_names_out()
    for center in centers:
        # 过滤数据到当前分拣中心
        center_data = data_sc[data_sc[center] == 1]
        if not center_data.empty:
            # 训练一个模型来预测货量
            X = (
                center_data[["日期"]]
                .apply(lambda x: x.dt.dayofyear)
                .values.reshape(-1, 1)
            )
            y = center_data["货量"].values
            model = RandomForestRegressor(n_estimators=100, random_state=42)
            model.fit(X, y)

            # 使用模型预测未来的货量
            future_X = (
                future_data["日期"].apply(lambda x: x.dayofyear).values.reshape(-1, 1)
            )
            future_y = model.predict(future_X)
            for date, volume in zip(future_dates, future_y):
                cleaned_center_name = center.replace("x0_分拣中心_", "")
                future_volumes.append(
                    [cleaned_center_name, date.strftime("%Y/%m/%d"), volume]
                )

    future_volumes_df = pd.DataFrame(
        future_volumes, columns=["分拣中心", "日期", "货量"]
    )

    # 考虑附件4的流通路径变更
    future_volumes_df.set_index(["分拣中心", "日期"], inplace=True)
    for index, row in data_changes.iterrows():
        from_center = "x0_分拣中心_" + row["始发分拣中心"]
        to_center = "分拣中心_" + row["到达分拣中心"]
        if from_center in centers:
            # 分配部分货量到新的目的地
            future_volumes_df.loc[(to_center,), "货量"] += (
                future_volumes_df.loc[(from_center,), "货量"] * 0.1
            )
            future_volumes_df.loc[(from_center,), "货量"] *= 0.9

    # 重置索引以符合输出格式
    future_volumes_df.reset_index(inplace=True)

    return future_volumes_df


def main():
    data_sc, data_routes, data_changes = load_data()
    data_sc, ohe = preprocess_data(data_sc, data_changes)
    future_volumes_df = predict_future_volume(data_sc, ohe, data_changes)
    future_volumes_df.to_csv("predicted_future_volumes.csv", index=False)
    print("预测完成，结果已保存到 'predicted_future_volumes.csv'")


if __name__ == "__main__":
    main()
\end{lstlisting}

\section{问题四代码}
\begin{lstlisting}[language=python]
import pandas as pd
from pulp import LpProblem, LpMinimize, LpVariable, lpSum, LpBinary, PULP_CBC_CMD

# 读取数据
df = pd.read_csv("for_read.csv")
df["date"] = pd.to_datetime(df["date"]).dt.date

# 班次及时间段
shifts = [(0, 8), (5, 13), (8, 16), (12, 20), (14, 22), (16, 24)]
shift_labels = ["Shift1", "Shift2", "Shift3", "Shift4", "Shift5", "Shift6"]
dates = sorted(df["date"].unique())

# 计算每个班次的需求
demand_per_shift = {date: {} for date in dates}
for date in dates:
    daily_data = df[df["date"] == date]
    for label, (start, end) in zip(shift_labels, shifts):
        demand_per_shift[date][label] = daily_data[
            (daily_data["hour"] >= start) & (daily_data["hour"] < end)
        ]["value"].sum()

# 建立优化模型
model = LpProblem("Personnel_Scheduling", LpMinimize)

# 定义变量
full_time = LpVariable.dicts(
    "FullTime", (dates, shift_labels, range(200)), 0, 1, LpBinary
)
temp_workers = LpVariable.dicts(
    "TempWorkers", (dates, shift_labels), 0, None, cat="Integer"
)

# 目标函数：最小化总人天数
model += lpSum(
    full_time[date][shift][i]
    for date in dates
    for shift in shift_labels
    for i in range(200)
) + lpSum(temp_workers[date][shift] for date in dates for shift in shift_labels)

# 每个班次的需求必须被满足的约束
for date in dates:
    for shift in shift_labels:
        model += (
            25 * lpSum(full_time[date][shift][i] for i in range(200))
            + 20 * temp_workers[date][shift]
            >= demand_per_shift[date][shift]
        )

# 正式工的出勤率不超过85%
for i in range(200):
    model += (
        lpSum(full_time[date][shift][i] for date in dates for shift in shift_labels)
        <= 30 * 0.85
    )

# 正式工连续出勤天数不超过7天
for i in range(200):
    for d in range(len(dates) - 6):
        model += (
            lpSum(
                full_time[dates[d + k]][shift][i]
                for k in range(7)
                for shift in shift_labels
            )
            <= 7
        )
# 求解问题
model.solve(PULP_CBC_CMD(msg=1, threads=8,gapRel=0.001))
print("soolved")
# 收集结果并输出为CSV
results = []
for date in dates:
    for shift in shift_labels:
        for i in range(200):
            if full_time[date][shift][i].varValue > 0:
                results.append(
                    {
                        "Sorting_Center": "SC60",
                        "Date": date,
                        "Shift": shift,
                        "Employee": f"FullTime({i})",
                    }
                )
        temp_workers_count = int(temp_workers[date][shift].varValue)
        for j in range(temp_workers_count):
            results.append(
                {
                    "Sorting_Center": "SC60",
                    "Date": date,
                    "Shift": shift,
                    "Employee": f"Temp({j})",
                }
            )

# 创建DataFrame并保存到CSV
results_df = pd.DataFrame(results)
results_df.to_csv("scheduling_results.csv", index=False)
print("CSV file has been saved with the scheduling results.")
\end{lstlisting}


\end{document}